{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back to Jupyter Notebook\n",
    "\n",
    "We have designed this session to be either guided or self-guided.\n",
    "\n",
    "If you would prefer to follow along with the facilitator (guided), then concepts will be explained one-by-one and you will have the opportunity to test your understanding on practice questions\n",
    "\n",
    "Alternatively, you are welcome to work through this workbook at your own pace (self-guided), if you have questions then there will be plenty of support on hand to help you, but you may miss some specific nuances that the facilitator explains during the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning objectives:\n",
    " - to understand how the Pandas package can be used to work with data tables in Python\n",
    " - this includes basic data manipulation, filtering and aggregation\n",
    "\n",
    "##### Stretch objectives:\n",
    " - to see the parallels between each Pandas command and it's corresponding SQL command\n",
    " - to use Pandas to merge tables together\n",
    " - to import the PandaSQL package and use SQLite to manipulate data within a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap if-statements and for-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below are lines of code that can be re-arranged into a\n",
    "#   well functioning if-statement.\n",
    "#  Re-arrange and correct where necessary...\n",
    "\n",
    "x = 'x is less than 200'\n",
    "\n",
    "print('length is equal to 18')\n",
    "print 'length is not equal to 18'\n",
    "if len(x) = 18\n",
    "else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below are lines of code that can be re-arranged into a\n",
    "#   well functioning if-statement.\n",
    "#  Re-arrange and correct where necessary...\n",
    "\n",
    "x = 110\n",
    "\n",
    "print('x is between 100 and 200')\n",
    "print('x is less than 100')\n",
    "if x > 200\n",
    "else\n",
    "print('x is...')\n",
    "elif x < 100:\n",
    "print('... bigger than 200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What changes do we need to make to the code below\n",
    "#  so that it fits the following brief?\n",
    "\n",
    "# Print the numbers 1 to 20, one after the other\n",
    "\n",
    "for i in range(1,20)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What changes do we need to make to the code below\n",
    "#  so that it fits the following brief?\n",
    "\n",
    "# Create a loop which prints either 'divisible by 3'\n",
    "#  or 'not divisible' for the first N numbers\n",
    "\n",
    "if i % 3 = 0:\n",
    "print('divisible by 3')\n",
    "for i in range(1,N)\n",
    "N = 12\n",
    "print('not divisible')\n",
    "else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to work with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During this workshop we are going to need packages that\n",
    "#  do not automatically start with every Jupyter Notebook session\n",
    "\n",
    "# We use the import statement:\n",
    "import pandas as pd              # This imports functionality for working with data tables\n",
    "import os                        # Mainly used to navigate the folder structure on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next thing we need to do is get the data\n",
    "#  that we are going to use in this session...\n",
    "\n",
    "# Your faciliator will tell you where to get the data,\n",
    "#  you will need to save it on your local hard drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USING THE 'OS' PACKAGE\n",
    "\n",
    "# The .getcwd() method tells us what directory Python is working in:\n",
    "directory = os.getcwd()\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .chdir() method lets us change the working directory to something else.\n",
    "# We need to change it to where we saved the data:\n",
    "os.chdir(r'C:\\Users\\Joe Harris\\Desktop\\WS4\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly check that it actually changed:\n",
    "directory = os.getcwd()\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READING THE DATA\n",
    "# We recommend checking the file structure and file contents\n",
    "#  on your own computer first before looking to understand the code below\n",
    "\n",
    "# The facilitator will talk you through how the code below works.\n",
    "\n",
    "# This should recap from Workshop 1:\n",
    "#  - FOR LOOPS\n",
    "#  - IF STATEMENTS\n",
    "#  - STR & LEN functions\n",
    "#  - LIST DATA TYPE\n",
    "\n",
    "# But we will also introduce some new syntax.\n",
    "\n",
    "## IMPORTANT:\n",
    "# You do not need remember all the new syntax immediately.\n",
    "# This is mainly an opportunity to recap learning from before.\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "# Reading outcomes data.\n",
    "outcomes_data = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(directory):   # os.walk() creates a list of file details from a specified folder\n",
    "\n",
    "    for file in files:          # we want to execute the following code once for each file in our list\n",
    "        \n",
    "        filepath = root + os.sep + file\n",
    "        if file.endswith(\"outcomes.csv\"):\n",
    "            \n",
    "            outcomes_csv = pd.read_csv(filepath)   # pd.read_csv() is used to read data into a 'Pandas Dataframe'\n",
    "            outcomes_csv['Region'] = str(file[8:-len(\"-outcomes.csv\")]).capitalize()\n",
    "            outcomes_csv['Month'] = str(file[0:8])\n",
    "            outcomes_data = outcomes_data.append(outcomes_csv)\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "# Reading street data.\n",
    "street_data = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        filepath = root + os.sep + file\n",
    "        if file.endswith(\"street.csv\"):\n",
    "            street_csv = pd.read_csv(filepath)\n",
    "            street_csv['Region'] = str(file[8:-len(\"-street.csv\")]).capitalize()\n",
    "            street_csv['Month'] = str(file[0:8])\n",
    "            street_data = street_data.append(street_csv)\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "# Reading stopandsearch data.\n",
    "stopandsearch_data = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        filepath = root + os.sep + file\n",
    "        if file.endswith(\"stop-and-search.csv\"):\n",
    "            stopandsearch_csv = pd.read_csv(filepath)\n",
    "            stopandsearch_csv['Region'] = str(file[8:-len(\"-stop-and-search.csv\")]).capitalize()\n",
    "            stopandsearch_csv['Month'] = str(file[0:8])\n",
    "            stopandsearch_data = stopandsearch_data.append(stopandsearch_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STRETCH\n",
    "# We could make the code above more efficient using a function.\n",
    "#  If you want to see how this could work, then see 'Stretch Function' at the bottom of this Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECKING THE DATA\n",
    "# Let's quickly check the data looks as we would expect...\n",
    "#  The next three code blocks all use the .head() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outcomes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopandsearch_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief for today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Queen of England needs help deciding who to award the \"Thin Blue Line Trophy\" for the most successful police department in the UK, how can we use this data to do so?\n",
    "\n",
    "Most successful has been defined as:\n",
    " - having a high ratio of suspects charged\n",
    " - a decline in crime over the last year in the local area\n",
    " - patrolling safer streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a group we will discuss how the data we have could\n",
    "# be used to determine the most successful police department\n",
    "\n",
    "# Ideas could be grouped into 4 categories:\n",
    "#  1. easily achievable with the tools we will cover in this session\n",
    "#  2. requires a small amount of independent research to learn additional skills beyond the session\n",
    "#  3. not possible with the data we have\n",
    "#  4. difficult to achieve through data analytics alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at outcomes data, compare numbers of crimes by outcome type, and define outcome types as pos/neg\n",
    "# Can't do second question - need more\n",
    "# Count stop and searches, not enough specificity\n",
    "# Look at % coverage of streets\n",
    "# Adjust for population\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basics for exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The .columns method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use the .columns method to see what columns we have in a Dataframe\n",
    "outcomes_c = outcomes_data.columns\n",
    "print(outcomes_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(street_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 1 ** #\n",
    "# Use the space below to create a new variable called 'street_c'\n",
    "#  which contains the columns of street_data, and then print it.\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "street_c = street_data.columns\n",
    "print(street_c)\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 1 *** #\n",
    "\n",
    "# 1. Create a new variable called 'sas_c' which contains the columns of stopandsearch_data\n",
    "# 2. Convert the variable 'sas_c' into list format\n",
    "# 3. Create a variable called street_column_2 that contains the second column of street_data\n",
    "# 4. Print an integer which represents the number of columns of street_data (use the len function)\n",
    "\n",
    "# What SQL code could you use to produce similar results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_c = stopandsearch_data.columns\n",
    "print(sas_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_c = list(sas_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sas_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_column_2 = list(street_c)[-1]\n",
    "print(street_column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We select a specific column of a Dataframe using square brackets:\n",
    "outcomes_data['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also select several columns using a list within square brackets:\n",
    "outcomes_data[['Location','Month','Falls within','LSOA name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using square brackets, we can create new Dataframes that only contain some columns:\n",
    "new_outcomes_data = outcomes_data[['Location','Month','Falls within','LSOA name']]\n",
    "\n",
    "new_outcomes_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 2 ** #\n",
    "\n",
    "# Use the space below to create:\n",
    "#  - a new variable called street_region, which contains the data from the 'Region' column in the street_data Dataframe\n",
    "#  - a new variable called sas_gender, which contains the 'Gender' column from stopandsearch_data\n",
    "#  - a new dateframe called first_four_c, which contains only the first 4 columns of street_data.\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 2 *** #\n",
    "\n",
    "# 1. Write a piece of code which starts by setting a value for \"N\",\n",
    "#     e.g. \"N = 5\"\n",
    "#    And then prints the first N columns of the stopandsearch_data Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Pandas methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNIQUE ##\n",
    "\n",
    "# The .unique() method will return a list containing all the unique values within a specified columns\n",
    "stop_search_types = stopandsearch_data['Gender'].unique()\n",
    "\n",
    "print(stop_search_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VALUE_COUNTS ##\n",
    "\n",
    "# The .value_counts() method will return how often each unique value appears within a specified column\n",
    "stopandsearch_data['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SORT_VALUES ##\n",
    "\n",
    "# The .sort_values() method will sort a Dataframe according to specified columns:\n",
    "\n",
    "sort_by_lat = stopandsearch_data.sort_values('Latitude')\n",
    "print(sort_by_lat[['Latitude']].head(3))\n",
    "\n",
    "sort_by_lat_desc = stopandsearch_data.sort_values('Latitude', ascending=False)\n",
    "print(sort_by_lat_desc[['Latitude']].head(3))\n",
    "\n",
    "sort_by_type_lat = stopandsearch_data.sort_values(['Type','Latitude'])\n",
    "print(sort_by_type_lat[['Type','Latitude']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 3 ** #\n",
    "\n",
    "# Use the space below to create:\n",
    "#  - a new list variable called street_regions, which contains all the different values for region in street_data\n",
    "#  - a new object called street_region_counts, which contains counts for the number of rows from each region in street_data\n",
    "#  - a new object called sorted_by_region, in which the data is sorted by region in reverse alphabetical order.\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 3 *** #\n",
    "\n",
    "# Answer the following questions:\n",
    "#  1. Which region has the most crime?\n",
    "#  2. In which region do the most stop and searches happen?\n",
    "#  3. Which LSOA has the most crime?\n",
    "#  4. Which search reason results in the most stop and searches?\n",
    "\n",
    "# What SQL code could you use to produce similar results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use the pd.DataFrame method to convert objects\n",
    "#   that look like the could be dataframes into Pandas dataframe.\n",
    "\n",
    "street_region_counts = street_data['Region'].value_counts()\n",
    "print('The result here is not a Pandas dataframe but it is presented as a table:')\n",
    "print(street_region_counts)\n",
    "print('')\n",
    "\n",
    "street_region_counts = pd.DataFrame(street_region_counts)\n",
    "print('We can reformat it as a Pandas dataframe:')\n",
    "print(street_region_counts)\n",
    "print('')\n",
    "\n",
    "street_region_counts = street_region_counts.reset_index()\n",
    "print('Resetting the index will make the index into a column:')\n",
    "print(street_region_counts)\n",
    "print('')\n",
    "\n",
    "street_region_counts.columns = ['Region','count']\n",
    "print('And we can rename the columns manually:')\n",
    "print(street_region_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 4 ** #\n",
    "\n",
    "# Create an object with value counts for LSOA in the street_data dataframe,\n",
    "#  and convert it into a Pandas dataframe, with sensible column names.\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "\n",
    "lsoa_counts = street_data['LSOA name'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The numpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import another package...\n",
    "import numpy as np     # This imports functionality for working with arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numpy package is used when working with arrays of numeric data,\n",
    "#  it has many functions which we do not explore in this session.\n",
    "\n",
    "# However, it is also useful when working with Pandas dataframes.\n",
    "# Each column in a Pandas dataframe can be treated as an array,\n",
    "#  meaning that we can use numpy functions, if the data is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_region_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy includes a function to find the sum of all values in an array\n",
    "np.sum(street_region_counts['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy includes a function to find the mean value in an array\n",
    "np.mean(street_region_counts['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy includes a function to find the median value in an array\n",
    "np.median(street_region_counts['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 5 ** #\n",
    "\n",
    "# Answer the following questions:\n",
    "#  1. What is the average number of crimes reported per LSOA in September?\n",
    "#  2. What is the median number of crimes reported per LSOA in September?\n",
    "#  3. What is the total number of crimes reported across all LSOAs?\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 5 *** #\n",
    "\n",
    "# Answer the following questions:\n",
    "#  1. What are the mean longitude and latitudes for a crime in outcomes_data?\n",
    "#  2. What are the mean longitude and latitudes for a crime in street_data?\n",
    "#  3. What are the mean longitude and latitudes for a crime in stopandsearch_data?\n",
    "#  4. What are the northern-, southern-, eastern-, and western-most extremes in outcomes_data?\n",
    "#      use np.min() and np.max()\n",
    "\n",
    "# What SQL code could you use to produce similar results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pandas SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More or less everything that we have done so far in this workshop could also be achieved using SQL. And technically, you can pass this course using SQL only. However, SQL is limited in its capabilities, and so we want to arm you with knowledge of Python.\n",
    "\n",
    "A skilled data analyst has multiple tools at their disposal using the most appropriate, depending on the situation. For example, an analyst may do most data manipulation, modelling, and visualisation in Python, but use SQL when initially extracting data from a well-maintained relational database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having said all that, we understand if you would prefer to practice your SQL coding for now, rather than cluttering your learning with new Pandas methods that achieve the same things as we can in SQL.\n",
    "\n",
    "Therefore, we are introducing a useful package called Pandas SQL, which allows you to use SQL within a Python script or Jupyter Notebook. Before we can use it, we need to install it first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next few sections:\n",
    "- Filtering\n",
    "- Aggregating\n",
    "- Merging\n",
    "\n",
    "Obviously, there is a lot of overlap between what you have already learnt in SQL and the content of these next three sections. We will advise you during the workshop whether to primarily use Pandas normally, or SQL via Pandasql, for the remaining sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installing a new package\n",
    "\n",
    "# The module that we want to use is called 'sqldf' from the 'pandasql' package.\n",
    "# But if we try to import it now, we might see an error:\n",
    "\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unless you have already installed the 'pandasql' package,\n",
    "#  you will need to do that now.\n",
    "\n",
    "!pip install -U pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once that is done, we can import the module, as shown below.\n",
    "# We also need to run the second statement below too before starting to use the package.\n",
    "\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the new sqldf function from Pandas we use the following structure:\n",
    "\n",
    "new_dataframe = sqldf(\" SQL QUERY \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, earlier we used the following code to find crime counts per LSOA:\n",
    "street_lsoa_counts = pd.DataFrame(street_data['LSOA name'].value_counts()).reset_index()\n",
    "street_lsoa_counts.columns = ['LSOA name','count']\n",
    "print(street_lsoa_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could achieve the same thing by using this code instead:\n",
    "street_lsoa_counts = sqldf(\"\"\"\n",
    "  SELECT\n",
    "    `LSOA name` AS lsoa,\n",
    "    count(`LSOA name`) AS count\n",
    "  FROM street_data\n",
    "  GROUP BY lsoa\n",
    "  ORDER BY count DESC\n",
    "\"\"\")\n",
    "print(street_lsoa_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's see what happens when we run the following code:\n",
    "true_false = (stopandsearch_data['Gender'] == 'Female')\n",
    "print(true_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# That code creates a Boolean array that we can use to filter data.\n",
    "\n",
    "# If we put an array of Trues/Falses into square brackets, then\n",
    "#  the data will be filtered to only those rows where the value is 'True'\n",
    "stopandsearch_data[true_false]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Or alternatively, we can put the condition straight into the square brackets:\n",
    "stopandsearch_data[stopandsearch_data['Gender'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could achieve the same thing by using this code instead:\n",
    "x = sqldf(\"\"\"\n",
    "  SELECT * FROM stopandsearch_data WHERE Gender = 'Female';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 6 ** #\n",
    "# Create a new dataframe called \"only_over_34\" which contains all columns\n",
    "#  from stopandsearch_data, but only where \"Age range\" is equal to \"over 34\".\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "only_over_34 = sqldf(\"\"\"\n",
    "  SELECT * FROM stopandsearch_data WHERE `Age range` = 'over 34';\n",
    "\"\"\")\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 6 *** #\n",
    "\n",
    "# Answer the following questions:\n",
    "#  1. What is the mean latitude for crimes in outcomes_data with the Outcome type, \"Unable to prosecute suspect\"?\n",
    "#  2. What is the mean latitude for crimes in street_data with the Crime type, \"Anti-social behaviour\"?\n",
    "#  3. What is the mean latitude for crimes in stopandsearch_data with the Object of search, \"Fireworks\"?\n",
    "\n",
    "# What SQL code could you use to produce similar results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating new calculated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can create new Pandas columns simply by assigning them a value,\n",
    "#   like we would with a normal variable...\n",
    "\n",
    "outcomes_data['always_three'] = 3   # This would create a column call 'always_three'\n",
    "                                    #  that takes the value of '3' for every row...\n",
    "outcomes_data[['Crime ID','Month','Latitude','always_three']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also base the new column off a pre-existing column or array...\n",
    "\n",
    "outcomes_data['new_latitude'] = outcomes_data['Latitude'] + 1   # 'new_latitude' would have the same values as\n",
    "                                                                #  latitude, but increased by 1 each time\n",
    "outcomes_data[['Crime ID','Month','Latitude','always_three','new_latitude']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or we could use a calculation from two pre-existing columns...\n",
    "\n",
    "outcomes_data['latitude_diff'] = outcomes_data['new_latitude'] - outcomes_data['Latitude']\n",
    "\n",
    "outcomes_data[['Crime ID','Month','Latitude','always_three','new_latitude','latitude_diff']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 7 ** #\n",
    "# The code below creates a Pandas dataframe containing crime\n",
    "#  counts for each region...\n",
    "\n",
    "street_region_counts = street_data['Region'].value_counts()\n",
    "street_region_counts = pd.DataFrame(street_region_counts)\n",
    "street_region_counts = street_region_counts.reset_index()\n",
    "street_region_counts.columns = ['Region','count']\n",
    "\n",
    "# Make changes to the dataframe 'street_region_counts' so that\n",
    "#  we have a column containing the percentage of crimes which occur\n",
    "#  in each area\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "# The step we need to take:\n",
    "#  - find the total number of crimes commited across all regions\n",
    "#  - add a column which is always equal to the total number of crimes commited\n",
    "#  - divide one column by the other to get a percentage for each region\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 7 *** #\n",
    "\n",
    "# Add a new column called 'latitude_is_na' to outcomes_data which takes the value of;\n",
    "#  - 'yes' when the value of 'Latitude' is NaN\n",
    "#  - 'no' when the value of 'Latitude' is not NaN\n",
    "\n",
    "# You will need to use the np.where(<condition>, <value if true>, <value if false>) function from numpy.\n",
    "# You will also need to use the np.isnan(<array>) function.\n",
    "\n",
    "# For example...\n",
    "print(np.where(street_region_counts['count'] > 10000, 1, 0))\n",
    "print('')\n",
    "print(np.isnan(outcomes_data['Longitude']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using .groupby to aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just as with SQL, we can aggregate Pandas dataframe with\n",
    "#   the .groupby() method\n",
    "\n",
    "# The following two statement produce very similar results:\n",
    "statement_1 = street_data['Region'].value_counts()\n",
    "statement_2 = street_data.groupby('Region')['LSOA name'].count()\n",
    "\n",
    "# How would this look in SQL? (answer below in stretch section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the group by method to find the\n",
    "#  mean, median, max, min, etc.\n",
    "\n",
    "# The code below finds the average longitude and latitude\n",
    "#  for each region:\n",
    "region_coordinates = street_data.groupby('Region')[['Longitude','Latitude']].mean()\n",
    "region_coordinates = pd.DataFrame(region_coordinates).reset_index()\n",
    "region_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could achieve the same thing by using this code instead:\n",
    "x = sqldf(\"\"\"\n",
    "  SELECT\n",
    "    Region,\n",
    "    AVG(Longitude) AS avg_longitude,\n",
    "    AVG(Latitude) AS avg_latitude\n",
    "  FROM street_data\n",
    "  GROUP BY Region;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 8 ** #\n",
    "# Create a new dataframe called \"lsoa_coordinates\" which contains the\n",
    "#  average longitude and latitude for each LSOA in outcomes_data.\n",
    "# The dataframe should have three columns named: 'lsoa', 'long', 'lat'\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 8 *** #\n",
    "\n",
    "# Modify your answer to Task 8 so that it also has a column\n",
    "#  called 'crime_count' which contains the number of crimes\n",
    "#  in each LSOA.\n",
    "\n",
    "# It is possible to do this in one step:\n",
    "#  Try googling \"group by pandas multiple functions\"\n",
    "\n",
    "# What SQL code could you use to produce similar results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally, we can also merge Pandas dataframes together\n",
    "#   just as we used SQL to perform joins.\n",
    "\n",
    "# Perhaps we want to merge outcomes_data with street_data\n",
    "#  so that we can have the crime type and outcome type\n",
    "#  in the same table:\n",
    "\n",
    "print(outcomes_data[['Crime ID','Outcome type']].head(3))\n",
    "print(street_data[['Crime ID','Crime type']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can merge them like this:\n",
    "left_table = outcomes_data[['Crime ID','Outcome type']]\n",
    "right_table = street_data[['Crime ID','Crime type']]\n",
    "\n",
    "new_merged_table = left_table.merge(right_table, left_on='Crime ID', right_on='Crime ID', how='inner')\n",
    "\n",
    "print(new_merged_table.head(3))\n",
    "print(len(new_merged_table))\n",
    "\n",
    "# We can also do left, right, and outer joins, just like in SQL.\n",
    "# Let's test them now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could achieve the same thing by using this code instead:\n",
    "x = sqldf(\"\"\"\n",
    "  SELECT\n",
    "    a.*, b.*\n",
    "  FROM outcomes_data a\n",
    "  INNER JOIN street_data b ON a.`Crime ID` = b.`Crime ID`;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Task 8 ** #\n",
    "# We want to compare the level of crime in two of the original datasets\n",
    "#  - outcomes_data, street_data -\n",
    "# by region, to see if some regions are over-represented in one dataset.\n",
    "\n",
    "# First use the space below to adapt the following code, so that it creates\n",
    "#  a new dataset with value counts for street_data:\n",
    "outcomes_counts = outcomes_data.groupby('Region')['LSOA name'].count()\n",
    "outcomes_counts = pd.DataFrame(outcomes_counts).reset_index()\n",
    "outcomes_counts.columns = ['region', 'count']\n",
    "\n",
    "# Once you have done that, merge the two datasets together by region (outer join).\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Stretch 8 *** #\n",
    "\n",
    "# 1. Add stopandsearch_data to the table created in Task 8\n",
    "#    What single SQL query could you use to combine all three tables in one step?\n",
    "\n",
    "# 2. Create new columns in your merged table to show how much each region\n",
    "#    is over-represented within each of the original datasets\n",
    "\n",
    "# (for example, you could create a ratio between the count from outcomes_data\n",
    "#  and the count from street_data, and see which region has the biggest index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STRETCH FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read data.\n",
    "def read_data_loop(name):\n",
    "\n",
    "    output_file = pd.DataFrame()\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = root + os.sep + file\n",
    "            if file.endswith(name+\".csv\"):\n",
    "                new_csv = pd.read_csv(filepath)\n",
    "                new_csv['Region'] = str(file[8:-len(\"-\"+name+\".csv\")]).capitalize()\n",
    "                new_csv['Month'] = str(file[0:8])\n",
    "                output_file = output_file.append(new_csv, sort=False)\n",
    "                \n",
    "    return(output_file)\n",
    "\n",
    "# --------------------------------------------------- #\n",
    "\n",
    "# Use the function three times for each type of data\n",
    "outcomes_data = read_data_loop('outcomes')\n",
    "street_data = read_data_loop('street')\n",
    "stopandsearch_data = read_data_loop('stop-and-search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL EQUIVALENT OF GROUP BY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;Region,\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;count(CrimeID) as crime_count\n",
    "<br>\n",
    "FROM street_data\n",
    "<br>\n",
    "GROUP BY Region;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
